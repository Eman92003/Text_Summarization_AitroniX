{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook aimes to try diffrernt summarization models from hugging face, We will try: <br>\n",
    "- PEGASUS (English summary) <br>\n",
    "- BAART (English summary) <br>\n",
    "- T5 (Multilangual summary) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T11:41:59.216474Z",
     "iopub.status.busy": "2026-01-08T11:41:59.216108Z",
     "iopub.status.idle": "2026-01-08T11:41:59.225037Z",
     "shell.execute_reply": "2026-01-08T11:41:59.224093Z",
     "shell.execute_reply.started": "2026-01-08T11:41:59.216436Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "PEGASUS = \"google/pegasus-cnn_dailymail\"\n",
    "BART = \"facebook/bart-large-cnn\"\n",
    "T5 = \"csebuetnlp/mT5_multilingual_XLSum\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T11:42:00.710363Z",
     "iopub.status.busy": "2026-01-08T11:42:00.710039Z",
     "iopub.status.idle": "2026-01-08T11:42:00.715321Z",
     "shell.execute_reply": "2026-01-08T11:42:00.714448Z",
     "shell.execute_reply.started": "2026-01-08T11:42:00.710333Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "English_text ='''\n",
    "Remote work expanded quickly after many companies invested in cloud tools and online collaboration.\n",
    "Employees often report benefits such as reduced commuting time, more flexible schedules, and improved\n",
    "focus for individual tasks. However, managers also highlight challenges, including weaker informal\n",
    "communication, difficulty onboarding new hires, and increased security risks if personal devices are \n",
    "not properly managed. As a result, many organizations are adopting hybrid policies, combining in-office\n",
    "days for teamwork with remote days for deep work, while updating guidelines for security, meetings, \n",
    "and performance evaluation\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T11:42:01.409349Z",
     "iopub.status.busy": "2026-01-08T11:42:01.408894Z",
     "iopub.status.idle": "2026-01-08T11:42:01.414378Z",
     "shell.execute_reply": "2026-01-08T11:42:01.413388Z",
     "shell.execute_reply.started": "2026-01-08T11:42:01.409314Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Arabic_text = '''\n",
    "شهدت المدن الكبرى في السنوات الأخيرة توسعًا سريعًا في استخدام تطبيقات \n",
    "توصيل الطعام، وهو ما غيّر عادات الشراء لدى كثير من الأسر. من جهة، وفّرت هذه الخدمات وقتًا وجهدًا وساعدت مطاعم صغيرة على الوصول لعملاء جدد. \n",
    "ومن جهة أخرى، ارتفعت شكاوى بعض المستخدمين من زيادة الرسوم وتفاوت جودة الخدمة وتأخر الطلبات في أوقات الذروة. كما أشار مختصون إلى أن الاعتماد \n",
    "الزائد على الوجبات الجاهزة قد يؤثر على العادات الغذائية، ما يدفع بعض المبادرات المحلية لتشجيع خيارات صحية وتقديم معلومات أوضح عن المكونات والسعرات.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **PEGASUS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2026-01-08T11:42:04.078489Z",
     "iopub.status.busy": "2026-01-08T11:42:04.077660Z",
     "iopub.status.idle": "2026-01-08T11:42:22.202279Z",
     "shell.execute_reply": "2026-01-08T11:42:22.201382Z",
     "shell.execute_reply.started": "2026-01-08T11:42:04.078454Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.52.4\n",
      "  Downloading transformers-4.52.4-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.52.4) (3.20.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.52.4) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.52.4) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.52.4) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.52.4) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.52.4) (2025.11.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.52.4) (2.32.5)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers==4.52.4)\n",
      "  Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers==4.52.4) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.52.4) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.4) (2025.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.4) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.4) (1.2.1rc0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.52.4) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.52.4) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.52.4) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.52.4) (2025.11.12)\n",
      "Downloading transformers-4.52.4-py3-none-any.whl (10.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tokenizers, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.22.1\n",
      "    Uninstalling tokenizers-0.22.1:\n",
      "      Successfully uninstalled tokenizers-0.22.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.57.1\n",
      "    Uninstalling transformers-4.57.1:\n",
      "      Successfully uninstalled transformers-4.57.1\n",
      "Successfully installed tokenizers-0.21.4 transformers-4.52.4\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.52.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T11:57:51.649439Z",
     "iopub.status.busy": "2026-01-08T11:57:51.649129Z",
     "iopub.status.idle": "2026-01-08T11:57:51.653894Z",
     "shell.execute_reply": "2026-01-08T11:57:51.652887Z",
     "shell.execute_reply.started": "2026-01-08T11:57:51.649413Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T11:45:23.802377Z",
     "iopub.status.busy": "2026-01-08T11:45:23.802003Z",
     "iopub.status.idle": "2026-01-08T11:46:21.684921Z",
     "shell.execute_reply": "2026-01-08T11:46:21.683355Z",
     "shell.execute_reply.started": "2026-01-08T11:45:23.802346Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d508b4e582f24cbdb71133c4697b4c16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/88.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7783c566652642f4bd42de0e94d44908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b53114cf78e04b079342c3c78f10650d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/1.91M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3cb79ce1c514f64b141a13ab8d37aca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-08 11:45:33.974098: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1767872734.196591      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1767872734.260014      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1767872734.784820      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1767872734.784856      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1767872734.784860      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1767872734.784863      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9c03cfb77f54dae82bf4a2f01cad734",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.28G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e921dbfc3084f0ab6f441e43f51382e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.28G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc115e4313e54baebdb2333bcfe5deb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/280 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer_p = AutoTokenizer.from_pretrained(PEGASUS)\n",
    "model_p = AutoModelForSeq2SeqLM.from_pretrained(PEGASUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T11:50:40.599727Z",
     "iopub.status.busy": "2026-01-08T11:50:40.599313Z",
     "iopub.status.idle": "2026-01-08T11:50:55.755522Z",
     "shell.execute_reply": "2026-01-08T11:50:55.754599Z",
     "shell.execute_reply.started": "2026-01-08T11:50:40.599694Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employees report benefits such as reduced commuting time, more flexible schedules, and improved focus on individual tasks .<n>However, managers also highlight challenges, including weaker informal communication, difficulty onboard new hires, and increased security risks .\n"
     ]
    }
   ],
   "source": [
    "input_English = tokenizer_p(\n",
    "    English_text,\n",
    "    return_tensors=\"pt\",\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=200\n",
    ")\n",
    "\n",
    "summary_ids_E = model_p.generate(\n",
    "    **input_English,\n",
    "    max_new_tokens=200,\n",
    "    num_beams=4,\n",
    "    no_repeat_ngram_size=3\n",
    ")\n",
    "\n",
    "print(tokenizer_p.decode(summary_ids_E[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T11:50:55.757520Z",
     "iopub.status.busy": "2026-01-08T11:50:55.757108Z",
     "iopub.status.idle": "2026-01-08T11:51:05.565624Z",
     "shell.execute_reply": "2026-01-08T11:51:05.564648Z",
     "shell.execute_reply.started": "2026-01-08T11:50:55.757490Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \"  \"<n> \"' '\"<n>' \" \"''' .<n>'' \"'\" .\n"
     ]
    }
   ],
   "source": [
    "input_Arabic = tokenizer_p(\n",
    "    Arabic_text,\n",
    "    return_tensors=\"pt\",\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=200\n",
    ")\n",
    "\n",
    "summary_ids_A = model_p.generate(\n",
    "    **input_Arabic,\n",
    "    max_new_tokens=200,\n",
    "    num_beams=4,\n",
    "    no_repeat_ngram_size=3\n",
    ")\n",
    "\n",
    "print(tokenizer_p.decode(summary_ids_A[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **As shown, this model is effecient on English text but not suitable for Arabic text**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **BART**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T11:52:47.882264Z",
     "iopub.status.busy": "2026-01-08T11:52:47.881848Z",
     "iopub.status.idle": "2026-01-08T11:52:56.571074Z",
     "shell.execute_reply": "2026-01-08T11:52:56.570138Z",
     "shell.execute_reply.started": "2026-01-08T11:52:47.882232Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbaf533339e145fa93efd89aeb29f30a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdbb59185dc041949375fa282e09a9e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f638b0af70a40d7bbca43df84a2cdc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7e0070b04ee425a990b0c573f5a6878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2034c00e7e143e1974d2da1719e8352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16836ad367cf439598bedd0a86a770d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer_b = AutoTokenizer.from_pretrained(BART)\n",
    "model_b = AutoModelForSeq2SeqLM.from_pretrained(BART)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T11:53:22.931539Z",
     "iopub.status.busy": "2026-01-08T11:53:22.931169Z",
     "iopub.status.idle": "2026-01-08T11:53:35.291126Z",
     "shell.execute_reply": "2026-01-08T11:53:35.290267Z",
     "shell.execute_reply.started": "2026-01-08T11:53:22.931505Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employees often report benefits such as reduced commuting time, more flexible schedules, and improved focus for individual tasks. However, managers also highlight challenges, including weaker informalcommunication and difficulty onboarding new hires. As a result, many organizations are adopting hybrid policies, combining in-office days for teamwork with remote days for deep work.\n"
     ]
    }
   ],
   "source": [
    "input_English = tokenizer_b(\n",
    "    English_text,\n",
    "    return_tensors=\"pt\",\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=200\n",
    ")\n",
    "\n",
    "summary_ids_E = model_b.generate(\n",
    "    **input_English,\n",
    "    max_new_tokens=200,\n",
    "    num_beams=4,\n",
    "    no_repeat_ngram_size=3\n",
    ")\n",
    "\n",
    "print(tokenizer_b.decode(summary_ids_E[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T11:54:34.342653Z",
     "iopub.status.busy": "2026-01-08T11:54:34.342281Z",
     "iopub.status.idle": "2026-01-08T11:54:45.589863Z",
     "shell.execute_reply": "2026-01-08T11:54:45.589009Z",
     "shell.execute_reply.started": "2026-01-08T11:54:34.342622Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                شهدت    ‘’’ ‘”’  “”  ”” ”,’,” ”,  , ”. “, ”.\n"
     ]
    }
   ],
   "source": [
    "input_Arabic = tokenizer_b(\n",
    "    Arabic_text,\n",
    "    return_tensors=\"pt\",\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=200\n",
    ")\n",
    "\n",
    "summary_ids_A = model_b.generate(\n",
    "    **input_Arabic,\n",
    "    max_new_tokens=200,\n",
    "    num_beams=4,\n",
    "    no_repeat_ngram_size=3\n",
    ")\n",
    "\n",
    "print(tokenizer_b.decode(summary_ids_A[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **As shown also, this model is effecient on English text but not suitable for Arabic text**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **T5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T11:56:14.818148Z",
     "iopub.status.busy": "2026-01-08T11:56:14.817783Z",
     "iopub.status.idle": "2026-01-08T11:56:38.840523Z",
     "shell.execute_reply": "2026-01-08T11:56:38.839308Z",
     "shell.execute_reply.started": "2026-01-08T11:56:14.818116Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0297584b0cd94603ab5c83d762da650f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/375 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f57ddf197c846778276e6208e85fdf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/730 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aedec2ec0db54dd4a0af2eb8897a3605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d65d4eaacabf4d02840e852574793de2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "/usr/local/lib/python3.12/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0a59c500c9a41228c40f58ad8b6a501",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe962a66385c4c61a0290d6ecc191e87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer_t = AutoTokenizer.from_pretrained(T5)\n",
    "model_t = AutoModelForSeq2SeqLM.from_pretrained(T5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T11:57:35.444545Z",
     "iopub.status.busy": "2026-01-08T11:57:35.443862Z",
     "iopub.status.idle": "2026-01-08T11:57:35.450034Z",
     "shell.execute_reply": "2026-01-08T11:57:35.449263Z",
     "shell.execute_reply.started": "2026-01-08T11:57:35.444512Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "/tmp/ipykernel_55/391913681.py:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  WHITESPACE_HANDLER = lambda k: re.sub('\\s+', ' ', re.sub('\\n+', ' ', k.strip()))\n"
     ]
    }
   ],
   "source": [
    "WHITESPACE_HANDLER = lambda k: re.sub('\\s+', ' ', re.sub('\\n+', ' ', k.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T11:58:11.541940Z",
     "iopub.status.busy": "2026-01-08T11:58:11.541598Z",
     "iopub.status.idle": "2026-01-08T11:58:30.130412Z",
     "shell.execute_reply": "2026-01-08T11:58:30.129544Z",
     "shell.execute_reply.started": "2026-01-08T11:58:11.541908Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "حذّرت وزارة الصحة البريطانية من أن استخدام تطبيقات توصيل الطعام قد يؤثر على العادات الغذائية.\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer_t(\n",
    "    [WHITESPACE_HANDLER(Arabic_text)],\n",
    "    return_tensors=\"pt\",\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=512\n",
    ")[\"input_ids\"]\n",
    "\n",
    "output_ids = model_t.generate(\n",
    "    input_ids=input_ids,\n",
    "    max_length=200,\n",
    "    no_repeat_ngram_size=2,\n",
    "    num_beams=4\n",
    ")[0]\n",
    "\n",
    "summary = tokenizer_t.decode(\n",
    "    output_ids,\n",
    "    skip_special_tokens=True,\n",
    "    clean_up_tokenization_spaces=False\n",
    ")\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T11:58:36.282833Z",
     "iopub.status.busy": "2026-01-08T11:58:36.282471Z",
     "iopub.status.idle": "2026-01-08T11:58:42.462848Z",
     "shell.execute_reply": "2026-01-08T11:58:42.461860Z",
     "shell.execute_reply.started": "2026-01-08T11:58:36.282804Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remote work is increasingly being used as a way of improving employment, according to new research.\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer_t(\n",
    "    [WHITESPACE_HANDLER(English_text)],\n",
    "    return_tensors=\"pt\",\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=512\n",
    ")[\"input_ids\"]\n",
    "\n",
    "output_ids = model_t.generate(\n",
    "    input_ids=input_ids,\n",
    "    max_length=200,\n",
    "    no_repeat_ngram_size=2,\n",
    "    num_beams=4\n",
    ")[0]\n",
    "\n",
    "summary = tokenizer_t.decode(\n",
    "    output_ids,\n",
    "    skip_special_tokens=True,\n",
    "    clean_up_tokenization_spaces=False\n",
    ")\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **This model works on both English and Arabic Text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
